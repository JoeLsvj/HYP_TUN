{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES for ht for regression\n",
    "\n",
    "HT to tune \n",
    "- lr \n",
    "- dropout \n",
    "- number of units \n",
    "- activation function \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import pandas\n",
    "import random\n",
    "import json, argparse\n",
    "\n",
    "# ML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from plotly import graph_objects as go\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "\n",
    "# pytorch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "\n",
    "# software modules\n",
    "import models_regression as Models\n",
    "import utils\n",
    "import dataset as Dataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet('/home/samuele/Desktop/22_dl/DL_Project/stocks_forecasting_LOB/Data/LOBSTER/MSFT.parquet')\n",
    "dataset = dataset.astype(float)\n",
    "dataset = dataset.head(3000) # try all or 20k\n",
    "#display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, axs = plt.subplots(2, 2, figsize=(24,12))\n",
    "#axs[0,0].plot(dataset['P_Ask_1'])\n",
    "#axs[0,1].plot(dataset['V_Ask_1'])\n",
    "#axs[1,0].plot(dataset['P_Bid_1'])\n",
    "#axs[1,1].plot(dataset['V_Bid_1'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'P_Ask_1'\n",
    "target_cols = []\n",
    "shifts = [ 1 ]\n",
    "\n",
    "for shift in shifts:\n",
    "    colname = f'Target_{shift}'\n",
    "    target_cols.append(colname)\n",
    "    dataset[colname] = dataset[target_col].shift(-shift)\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "#display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into train, validation and test\n",
    "dataset_train, dataset_val, dataset_test = utils.DataTools.train_val_test_split(dataset)\n",
    "\n",
    "# Standardize the data\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#scaler.fit(dataset_train)\n",
    "\n",
    "#dataset_train[dataset_train.columns] = scaler.transform(dataset_train)\n",
    "#dataset_val[dataset_val.columns] = scaler.transform(dataset_val)\n",
    "#dataset_test[dataset_test.columns] = scaler.transform(dataset_test)\n",
    "\n",
    "means = dataset_train.mean(axis=0)\n",
    "stds = dataset_train.std(axis=0)\n",
    "\n",
    "means[-len(target_cols):] = means[target_cols]\n",
    "stds[-len(target_cols):] = stds[target_cols]\n",
    "\n",
    "dataset_train = ( dataset_train - means ) / stds\n",
    "dataset_val = ( dataset_val - means ) / stds\n",
    "dataset_test = ( dataset_test - means ) / stds\n",
    "\n",
    "\n",
    "\n",
    "#display(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1900 samples\n",
      "Test dataset: 252 samples\n"
     ]
    }
   ],
   "source": [
    "# Split covariates and response variables\n",
    "X_train, y_train = utils.DataTools.split_x_y(dataset_train, target_cols)\n",
    "X_val, y_val = utils.DataTools.split_x_y(dataset_val, target_cols)\n",
    "X_test, y_test = utils.DataTools.split_x_y(dataset_test, target_cols)\n",
    "\n",
    "# Convert to pytorch tensors\n",
    "X_train, X_val, X_test = utils.DataTools.numpy_to_tensor( X_train, X_val, X_test, dtype=torch.float32 )\n",
    "y_train, y_val, y_test = utils.DataTools.numpy_to_tensor( y_train, y_val, y_test, dtype=torch.float32 )\n",
    "\n",
    "# Create Torch Dataset\n",
    "lookback_period = 100\n",
    "dataset_train = Dataset.TimeSeriesDataset(\n",
    "    X         = X_train,\n",
    "    y         = y_train,\n",
    "    seq_len_x = lookback_period,\n",
    "    seq_len_y = 1,\n",
    "    offset    = lookback_period-1,\n",
    "    channels  = False,\n",
    "    task      = Dataset.TimeSeriesDataset.Task.REGRESSION\n",
    ")\n",
    "dataset_val = Dataset.TimeSeriesDataset(\n",
    "    X         = X_val,\n",
    "    y         = y_val,\n",
    "    seq_len_x = lookback_period,\n",
    "    seq_len_y = 1,\n",
    "    offset    = lookback_period-1,\n",
    "    channels  = False,\n",
    "    task      = Dataset.TimeSeriesDataset.Task.REGRESSION\n",
    ")\n",
    "dataset_test = Dataset.TimeSeriesDataset(\n",
    "    X         = X_test,\n",
    "    y         = y_test,\n",
    "    seq_len_x = lookback_period,\n",
    "    seq_len_y = 1,\n",
    "    offset    = lookback_period-1,\n",
    "    channels  = False,\n",
    "    task      = Dataset.TimeSeriesDataset.Task.REGRESSION\n",
    ")\n",
    "\n",
    "# Create Torch DataLoader\n",
    "batch_size = 32\n",
    "dataloader_train = Dataset.TimeSeriesLoader(\n",
    "    dataset = dataset_train,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "dataloader_val = Dataset.TimeSeriesLoader(\n",
    "    dataset = dataset_val,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "dataloader_test = Dataset.TimeSeriesLoader(\n",
    "    dataset = dataset_test,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "print(f'Train dataset: {len(dataset_train)} samples')\n",
    "print(f'Test dataset: {len(dataset_test)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train.dataset.channels = False\n",
    "dataloader_val.dataset.channels = False\n",
    "dataloader_test.dataset.channels = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 0.8056619167327881, seconds\n",
      "Epoch 1/5, Train Loss: 0.12264361, Val Loss:  0.03998199, \n",
      "[==========----------------------------------------] 20.0%  starting epoch 2\n",
      "Duration of training epoch 2: 0.8575708866119385, seconds\n",
      "Epoch 2/5, Train Loss: 0.02727260, Val Loss:  0.03137778, \n",
      "[====================------------------------------] 40.0%  starting epoch 3\n",
      "Duration of training epoch 3: 0.7785418033599854, seconds\n",
      "Epoch 3/5, Train Loss: 0.02379880, Val Loss:  0.02963189, \n",
      "[==============================--------------------] 60.0%  starting epoch 4\n",
      "Duration of training epoch 4: 0.8181400299072266, seconds\n",
      "Epoch 4/5, Train Loss: 0.02243410, Val Loss:  0.02817853, \n",
      "[========================================----------] 80.0%  starting epoch 5\n",
      "Duration of training epoch 5: 0.9199349880218506, seconds\n",
      "Epoch 5/5, Train Loss: 0.01907012, Val Loss:  0.03024920, \n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "params = {\n",
    "    'input_size': X_train.shape[1],\n",
    "    'hidden_layer_size': 64,\n",
    "    'num_layers': 2,\n",
    "    'output_size': y_train.shape[1],\n",
    "    'dropout': 0.2\n",
    "}\n",
    "model = Models.LSTM1(**params).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "training_info = utils.ModelTools.train(\n",
    "    model_id = 'LSTM1',\n",
    "    model = model,\n",
    "    criterion = criterion,\n",
    "    optimizer = optimizer,\n",
    "    train_loader = dataloader_train,\n",
    "    val_loader = dataloader_val,\n",
    "    n_epochs = epochs,\n",
    "    save = False,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03188387728878297\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.mean(training_info['val_loss'][-5:])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_list = list(range(0,epochs))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(epochs_list, training_info['val_loss'],  label = \"validation error\")\n",
    "plt.plot(epochs_list, training_info['train_loss'], label = \"train error\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful commands \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.20, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837ceb7004fd409e96655544dc010fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will be saved.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "IPython.notebook.save_checkpoint();",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Useful libs\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time as time\n",
    "import sys # to stop the execution of the code\n",
    "from IPython.display import display, Javascript # to save \n",
    "import pygame # to sound\n",
    "\n",
    "# Display the progress bar\n",
    "\n",
    "def display_progress_bar(estimated_time, num_updates):\n",
    "    # Calculate the sleep interval between updates\n",
    "    sleep_interval = estimated_time / num_updates\n",
    "\n",
    "    # Display the progress bar\n",
    "    with tqdm(total=num_updates) as pbar:\n",
    "        for i in range(num_updates):\n",
    "            time.sleep(sleep_interval)\n",
    "            pbar.update(1)\n",
    "\n",
    "estimated_time = 1\n",
    "num_updates = 300\n",
    "\n",
    "display_progress_bar(estimated_time, num_updates)\n",
    "\n",
    "# Code before the exit\n",
    "\n",
    "#print(\"This will run\")\n",
    "#raise SystemExit(\"Stopping execution here.\")\n",
    "#print(\"This will not run\")\n",
    "\n",
    "\n",
    "# Save the notebook\n",
    "\n",
    "def save_notebook():\n",
    "    display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "print(\"This will be saved.\")\n",
    "save_notebook() # Save the notebook\n",
    "\n",
    "\n",
    "# To play a sound\n",
    "\n",
    "pygame.mixer.init() # Initialize the mixer module\n",
    "#sound = pygame.mixer.Sound('./sound1.wav') # Load a sound file (ensure you have a .wav file)\n",
    "#sound.play() # Play the sound\n",
    "#pygame.time.wait(int(sound.get_length() * 1000)) # Ensure the sound has time to play\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The EA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual: nn_gene = [512, 512], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.001, dropout = 0.2 | nn_sol = [512, 512], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "class Individual:\n",
    "    def __init__(self, structure_gene, af_gene, lr_gene, dropout_gene ,fitness=0.0):\n",
    "        \"\"\"\n",
    "        Initialize an individual with a gene, solution, and fitness.\n",
    "        \n",
    "        Parameters:\n",
    "        gene (float): The value in the space of the gene.\n",
    "        solution (Any): The value in the space of the solution.\n",
    "        fitness (float): The fitness value of the individual.\n",
    "        \"\"\"\n",
    "        self.structure_gene = structure_gene\n",
    "        self.af_gene = af_gene\n",
    "        self.lr_gene = lr_gene\n",
    "        self.dropout_gene = dropout_gene\n",
    "\n",
    "        self.structure_solution = self.from_structureGene_to_structureSolution(structure_gene)  \n",
    "        self.af_solution = self.af_gene\n",
    "        self.lr_solution = self.lr_gene\n",
    "        self.dropout_solution = self.dropout_gene\n",
    "\n",
    "        self.fitness = 0.0\n",
    "    \n",
    "    def from_structureGene_to_structureSolution(self, structureGenotype):\n",
    "        \"\"\"\n",
    "        Convert the gene to a solution.\n",
    "        \"\"\"\n",
    "        # For all element in the list of the genes, the solution is the list of the integer raund of the gene\n",
    "        return [round(g) for g in structureGenotype]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Individual: nn_gene = {self.structure_gene}, af = {self.af_gene}, lr = {self.lr_gene}, dropout = {self.dropout_gene} | nn_sol = {self.structure_solution}, Fitness = {self.fitness}\"\n",
    "\n",
    "# Example usage:\n",
    "ind = Individual([512, 512], nn.ReLU, 0.001, 0.2)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop\n",
      "Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.0\n",
      "Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.0\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.0\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.0\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.0\n",
      "\n",
      "An individual\n",
      "[377, 127, 570, 19]\n",
      "0.004069676109614568\n",
      "<class 'torch.nn.modules.activation.Tanh'>\n",
      "0.14571091681565093\n"
     ]
    }
   ],
   "source": [
    "def initialization(\n",
    "        initial_population_size,\n",
    "        number_of_layers_interval,\n",
    "        number_of_units_interval,\n",
    "        activation_functions,\n",
    "        learning_rate_interval,\n",
    "        dropout_interval):\n",
    "    \n",
    "    structure_genes = []\n",
    "    \n",
    "    for _ in range(initial_population_size):\n",
    "        num_layers = random.randint(number_of_layers_interval[0], number_of_layers_interval[1])\n",
    "        structure_gene = [random.randint(number_of_units_interval[0], number_of_units_interval[1]) for _ in range(num_layers)]\n",
    "        structure_genes.append(structure_gene)\n",
    "\n",
    "    af_genes = [random.choice(activation_functions) for _ in range(initial_population_size)]\n",
    "\n",
    "    lr_genes = [random.uniform(learning_rate_interval[0], learning_rate_interval[1]) for _ in range(initial_population_size)]\n",
    "\n",
    "    dropout_genes = [random.uniform(dropout_interval[0], dropout_interval[1]) for _ in range(initial_population_size)]\n",
    "    \n",
    "    individuals = [Individual(structure_gene, af_gene, lr_gene, dropout_gene) for structure_gene, af_gene, lr_gene, dropout_gene in zip(structure_genes, af_genes, lr_genes, dropout_genes)]\n",
    "\n",
    "    return individuals\n",
    "\n",
    "# Example usage\n",
    "population_size = 5\n",
    "number_of_layers_interval=[1, 5]\n",
    "number_of_units_interval=[10, 600]\n",
    "activation_functions=[nn.ReLU, nn.Sigmoid, nn.Tanh, nn.LeakyReLU, nn.ELU, nn.SELU]\n",
    "learning_rate_interval=[0.0001, 0.01]\n",
    "dropout_interval=[0, 0.2]\n",
    "\n",
    "population = initialization(\n",
    "    initial_population_size = population_size,\n",
    "    number_of_layers_interval = number_of_layers_interval,\n",
    "    number_of_units_interval = number_of_units_interval,\n",
    "    activation_functions = activation_functions,\n",
    "    learning_rate_interval = learning_rate_interval,\n",
    "    dropout_interval = dropout_interval)\n",
    "\n",
    "print(\"Pop\")\n",
    "for individual in population:\n",
    "    print(individual)\n",
    "\n",
    "print(\"\\nAn individual\")\n",
    "print(population[0].structure_gene)\n",
    "print(population[0].lr_gene)\n",
    "print(population[0].af_gene)\n",
    "print(population[0].dropout_gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness assessment\n",
    "\n",
    "UPDATE THIS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 12.494683742523193, seconds\n",
      "Epoch 1/1, Train Loss: 0.13502893, Val Loss:  0.02653606, \n"
     ]
    }
   ],
   "source": [
    "def fitness_evaluation(\n",
    "        individual,\n",
    "        training_data,\n",
    "        validation_data,\n",
    "        num_epochs_per_evaluation,\n",
    "        #lr,\n",
    "        input_size, # 40\n",
    "        #hidden_sizes,\n",
    "        output_size, # 15\n",
    "        #activation_function,\n",
    "        #initialize_weights,\n",
    "        #dropout,\n",
    "        device): \n",
    "\n",
    "    params = {\n",
    "        'input_size': input_size,\n",
    "        'hidden_layer_size': individual.structure_solution[0],\n",
    "        'num_layers': 2,\n",
    "        'output_size': output_size,\n",
    "        'dropout': individual.dropout_solution,\n",
    "    }\n",
    "    model = Models.LSTM1(**params).to(device)\n",
    "\n",
    "    # Optimizer parameters\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=individual.lr_solution)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    training_info = utils.ModelTools.train(\n",
    "        model_id = 'LSTM1',\n",
    "        model = model,\n",
    "        criterion = criterion,\n",
    "        optimizer = optimizer,\n",
    "        train_loader = training_data,\n",
    "        val_loader = validation_data,\n",
    "        n_epochs = num_epochs_per_evaluation,\n",
    "        save = False,\n",
    "        device = device)\n",
    "\n",
    "    return np.mean(training_info['val_loss'][-5:])\n",
    "    \n",
    "\n",
    "\n",
    "# Example usage:\n",
    "individual = population[0]\n",
    "training_data = dataloader_train\n",
    "validation_data = dataloader_val\n",
    "num_epochs_per_evaluation = 1\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "device = device\n",
    "\n",
    "fitness = fitness_evaluation(\n",
    "    individual = individual,\n",
    "    training_data = training_data,\n",
    "    validation_data = validation_data,\n",
    "    num_epochs_per_evaluation = num_epochs_per_evaluation, # just for testing\n",
    "    input_size = input_size,\n",
    "    output_size = output_size,\n",
    "    device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 11.482966423034668, seconds\n",
      "Epoch 1/1, Train Loss: 0.13406188, Val Loss:  0.02857480, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 20.152158498764038, seconds\n",
      "Epoch 1/1, Train Loss: 0.18057390, Val Loss:  0.02535562, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 25.160767316818237, seconds\n",
      "Epoch 1/1, Train Loss: 0.06233638, Val Loss:  0.02356214, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 9.622312068939209, seconds\n",
      "Epoch 1/1, Train Loss: 0.18180497, Val Loss:  0.02613769, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 7.570146799087524, seconds\n",
      "Epoch 1/1, Train Loss: 0.12290916, Val Loss:  0.03061703, \n",
      "Population:\n",
      "Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.02613769203890115\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.030617032636655495\n",
      "\n",
      "Fitnesses:\n",
      "0.02857479895465076\n",
      "0.025355623802170157\n",
      "0.023562137386761606\n",
      "0.02613769203890115\n",
      "0.030617032636655495\n"
     ]
    }
   ],
   "source": [
    "# Assess population\n",
    "def evaluate_individuals(\n",
    "        individuals,\n",
    "        training_data,\n",
    "        validation_data,\n",
    "        num_epochs_per_evaluation,\n",
    "        #lr,\n",
    "        input_size, # 40\n",
    "        #hidden_sizes,\n",
    "        output_size, # 15\n",
    "        #activation_function,\n",
    "        #initialize_weights,\n",
    "        #dropout,\n",
    "        device): \n",
    "    \n",
    "    for individual in individuals:\n",
    "        individual.fitness = fitness_evaluation(\n",
    "            individual = individual,\n",
    "            training_data = training_data,\n",
    "            validation_data = validation_data,\n",
    "            num_epochs_per_evaluation = num_epochs_per_evaluation,\n",
    "            #lr,\n",
    "            input_size = input_size, # 40\n",
    "            #hidden_sizes,\n",
    "            output_size = output_size, # 15\n",
    "            #activation_function,\n",
    "            #initialize_weights,\n",
    "            #dropout,\n",
    "            device = device)\n",
    "        \n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "#population = population\n",
    "training_data = dataloader_train    \n",
    "validation_data = dataloader_val\n",
    "num_epochs_per_evaluation = 1\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "device = device\n",
    "\n",
    "evaluate_individuals(\n",
    "    individuals = population,\n",
    "    training_data = training_data,\n",
    "    validation_data = validation_data,\n",
    "    num_epochs_per_evaluation = num_epochs_per_evaluation,\n",
    "    input_size = input_size,\n",
    "    output_size = output_size,\n",
    "    device = device)\n",
    "\n",
    "print(\"Population:\")\n",
    "for individual in population:\n",
    "    print(individual)\n",
    "\n",
    "print(\"\\nFitnesses:\")\n",
    "for individual in population:\n",
    "    print(individual.fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n"
     ]
    }
   ],
   "source": [
    "def find_best_individual(population, maximize):\n",
    "    \"\"\"\n",
    "    Find the individual with the best fitness value in the population.\n",
    "    \n",
    "    Parameters:\n",
    "    population (list): A list of Individual objects.\n",
    "    \n",
    "    Returns:\n",
    "    Individual: The individual with the best fitness value.\n",
    "    \"\"\"\n",
    "    if maximize:\n",
    "        best_individual = max(population, key=lambda x: x.fitness)\n",
    "    else:\n",
    "        best_individual = min(population, key=lambda x: x.fitness)\n",
    "    return best_individual\n",
    "\n",
    "# Example usage:\n",
    "#population: defined before\n",
    "maximize = False\n",
    "\n",
    "best_individual = find_best_individual(population = population, maximize = maximize)   \n",
    "print(best_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Population:\n",
      "Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.02613769203890115\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.030617032636655495\n",
      "\n",
      "Selected individuals:\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.030617032636655495\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.030617032636655495\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.02613769203890115\n"
     ]
    }
   ],
   "source": [
    "# Tournament selection\n",
    "# number_of_selected: The number of individuals to be selected.\n",
    "# percentage_of_population_size: The percentage of the population size to use for the tournament.\n",
    "# heterogeneity = True: If True, the selected individuals must be unique.\n",
    "def tournament_selection(population, number_of_selected, percentage_of_population_size, heterogeneity):\n",
    "    selected_individuals = []\n",
    "    tournament_size = max(1, int(len(population) * percentage_of_population_size))\n",
    "\n",
    "    for _ in range(number_of_selected):\n",
    "        if heterogeneity:\n",
    "            # Ensure uniqueness\n",
    "            best_individual = None\n",
    "            while best_individual is None or best_individual in selected_individuals:\n",
    "                # Randomly select individuals for the tournament\n",
    "                tournament_individuals = random.sample(population, tournament_size)\n",
    "                # Select the best individual from the tournament\n",
    "                best_individual = min(tournament_individuals, key=lambda ind: ind.fitness)\n",
    "        else:\n",
    "            # Randomly select individuals for the tournament\n",
    "            tournament_individuals = random.sample(population, tournament_size)\n",
    "            # Select the best individual from the tournament\n",
    "            best_individual = min(tournament_individuals, key=lambda ind: ind.fitness)\n",
    "\n",
    "        selected_individuals.append(best_individual)\n",
    "\n",
    "    return selected_individuals\n",
    "\n",
    "# Example usage:\n",
    "#population: defined before\n",
    "number_of_selected = 4\n",
    "percentage_of_population_size = 0.2 # 20% of the population size\n",
    "heterogeneity = False\n",
    "\n",
    "selected_individuals = tournament_selection(\n",
    "    population = population,\n",
    "    number_of_selected = number_of_selected,\n",
    "    percentage_of_population_size = percentage_of_population_size,\n",
    "    heterogeneity=heterogeneity)\n",
    "\n",
    "print(\"\\nPopulation:\")\n",
    "for individual in population:\n",
    "    print(individual)\n",
    "\n",
    "print(\"\\nSelected individuals:\")\n",
    "for individual in selected_individuals:\n",
    "    print(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Population:\n",
      "Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.02613769203890115\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.030617032636655495\n",
      "\n",
      "Selected individuals:\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.02613769203890115\n",
      "Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n"
     ]
    }
   ],
   "source": [
    "# Truncated selection\n",
    "# k: The number of individuals to be selected.\n",
    "# maximize: If True, select individuals with greatest fitness; otherwise, select individuals with smallest fitness.\n",
    "def truncated_selection(population, k, maximize):\n",
    "    # Sort the population based on fitness\n",
    "    sorted_population = sorted(population, key=lambda ind: ind.fitness, reverse=maximize)\n",
    "    \n",
    "    # Select the top k individuals\n",
    "    selected_individuals = sorted_population[:k]\n",
    "    \n",
    "    return selected_individuals\n",
    "\n",
    "# Example usage:\n",
    "# population: defined before\n",
    "k = 4\n",
    "maximize = False  # Change to True if you want to select individuals with greatest fitness\n",
    "\n",
    "selected_individuals = truncated_selection(population = population, k = k, maximize = maximize)\n",
    "\n",
    "print(\"\\nPopulation:\")\n",
    "for individual in population:\n",
    "    print(individual)\n",
    "\n",
    "print(\"\\nSelected individuals:\")\n",
    "for individual in selected_individuals:\n",
    "    print(individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary operators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossover operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: [16, inf]\n",
      "\n",
      "Gene: 1000, \n",
      "Corrected gene: 1000\n"
     ]
    }
   ],
   "source": [
    "def correct_layer_size(gene, lb, ub):\n",
    "    if gene < lb or gene > ub:\n",
    "        if gene < lb:\n",
    "            gene = lb\n",
    "        else:\n",
    "            gene = ub\n",
    "    return gene\n",
    "    \n",
    "# Example of usage \n",
    "gene = 1000\n",
    "lb = 16\n",
    "ub = np.inf\n",
    "\n",
    "corrected_gene = correct_layer_size(gene = gene, lb = lb, ub = ub)\n",
    "\n",
    "print(f\"Range: [{lb}, {ub}]\")\n",
    "print(f\"\\nGene: {gene}, \\nCorrected gene: {corrected_gene}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: [10, 100]\n",
      "\n",
      "Genotype: [0, 20, 150], \n",
      "Corrected genotype: [10, 20, 100]\n"
     ]
    }
   ],
   "source": [
    "def correct_layers_size(genotype, lb, ub):\n",
    "    corrected_genotype = [lb if gene < lb else ub if gene > ub else gene for gene in genotype]\n",
    "    return corrected_genotype\n",
    "\n",
    "# Example of usage\n",
    "genotype = [0, 20, 150]\n",
    "lb = 10\n",
    "ub = 100\n",
    "\n",
    "corrected_genotype = correct_layers_size(genotype = genotype, lb = lb, ub = ub)\n",
    "\n",
    "print(f\"Range: [{lb}, {ub}]\")\n",
    "print(f\"\\nGenotype: {genotype}, \\nCorrected genotype: {corrected_genotype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: [10, 50]\n",
      "\n",
      "Value: 1, \n",
      "Corrected value: 10\n"
     ]
    }
   ],
   "source": [
    "def correct_general_size(value, ub, lb):\n",
    "    if value < lb:\n",
    "        value = lb\n",
    "    elif value > ub:\n",
    "        value = ub\n",
    "    return value\n",
    "\n",
    "# Example of usage\n",
    "value = 1\n",
    "lb = 10\n",
    "ub = 50\n",
    "\n",
    "corrected_value = correct_general_size(value = value, ub = ub, lb = lb)\n",
    "\n",
    "print(f\"Range: [{lb}, {ub}]\")\n",
    "print(f\"\\nValue: {value}, \\nCorrected value: {corrected_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent 1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Parent 2: Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "\n",
      "Offspring2 CX: Individual: nn_gene = [377, 431], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 431], Fitness = 0.0\n",
      "Offspring1 CX: Individual: nn_gene = [577, 127, 570, 19], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 127, 570, 19], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Description:\n",
    "# aaa|aa \n",
    "# bbb|bb\n",
    "# --> aaa|bb, bbb|aa\n",
    "def structure_singlePointCX(parent1, parent2):\n",
    "    gene1, gene2 = parent1.structure_gene, parent2.structure_gene\n",
    "    af_gene1, af_gene2 = parent1.af_gene, parent2.af_gene\n",
    "    lr_gene1, lr_gene2 = parent1.lr_gene, parent2.lr_gene\n",
    "    if len(gene1) == 1 or len(gene2) == 1:\n",
    "        return parent1, parent2  # No crossover if a parent has only one layer\n",
    "    point = random.randint(1, min(len(gene1), len(gene2)) - 1)\n",
    "    child_gene1 = gene1[:point] + gene2[point:]\n",
    "    child_gene2 = gene2[:point] + gene1[point:]\n",
    "    child1 = Individual(structure_gene=child_gene1, af_gene=af_gene1, lr_gene=lr_gene1, dropout_gene=parent1.dropout_gene)\n",
    "    child2 = Individual(structure_gene=child_gene2, af_gene=af_gene2, lr_gene=lr_gene2, dropout_gene=parent2.dropout_gene)\n",
    "    return child1, child2\n",
    "\n",
    "# Exmaple usage\n",
    "parent1 = population[0]\n",
    "parent2 = population[2]\n",
    "offspring1, offspring2 = structure_singlePointCX(parent1, parent2)\n",
    "\n",
    "print(f\"Parent 1: {parent1}\")\n",
    "print(f\"Parent 2: {parent2}\")\n",
    "print(f\"\\nOffspring2 CX: {offspring1}\")\n",
    "print(f\"Offspring1 CX: {offspring2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent 1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Parent 2: Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "\n",
      "Offspring1: Individual: nn_gene = [577, 279.0], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [577, 279], Fitness = 0.0\n",
      "Offspring2: Individual: nn_gene = [477.0, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [477, 431], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "def structure_SPC_E(parent1, parent2):\n",
    "    gene1, gene2 = parent1.structure_gene, parent2.structure_gene\n",
    "    af_gene1, af_gene2 = parent1.af_gene, parent2.af_gene\n",
    "    lr_gene1, lr_gene2 = parent1.lr_gene, parent2.lr_gene\n",
    "    \n",
    "    # Determine the fittest parent\n",
    "    if parent1.fitness < parent2.fitness:\n",
    "        fitter_parent = parent1\n",
    "        other_parent = parent2\n",
    "    else:\n",
    "        fitter_parent = parent2\n",
    "        other_parent = parent1\n",
    "\n",
    "    if len(gene1) == 1 or len(gene2) == 1:\n",
    "        return parent1, parent2  # No crossover if a parent has only one layer\n",
    "    \n",
    "    point = random.randint(1, min(len(gene1), len(gene2)) - 1)\n",
    "    \n",
    "    # Split genes at the crossover point\n",
    "    first_part_fitter = fitter_parent.structure_gene[:point]\n",
    "    second_part_fitter = fitter_parent.structure_gene[point:]\n",
    "    \n",
    "    first_part_other = other_parent.structure_gene[:point]\n",
    "    second_part_other = other_parent.structure_gene[point:]\n",
    "    \n",
    "    # Compute averages for the second part of genes\n",
    "    avg_second_part = [(a + b) / 2 for a, b in zip(second_part_fitter, second_part_other)]\n",
    "    avg_first_part = [(a + b) / 2 for a, b in zip(first_part_fitter, first_part_other)]\n",
    "    \n",
    "    # Create new genes for the children\n",
    "    child_gene1 = first_part_fitter + avg_second_part\n",
    "    child_gene2 = avg_first_part + second_part_fitter\n",
    "    \n",
    "    # Create child individuals\n",
    "    child1 = Individual(structure_gene=child_gene1, af_gene=af_gene1, lr_gene =lr_gene1, dropout_gene=parent1.dropout_gene)\n",
    "    child2 = Individual(structure_gene=child_gene2, af_gene=af_gene2, lr_gene =lr_gene2, dropout_gene=parent2.dropout_gene)\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "# Example usage\n",
    "parent1 = population[0]\n",
    "parent2 = population[2]\n",
    "offspring1, offspring2 = structure_SPC_E(parent1, parent2)\n",
    "\n",
    "print(f\"Parent 1: {parent1}\")\n",
    "print(f\"Parent 2: {parent2}\")\n",
    "print(f\"\\nOffspring1: {offspring1}\")\n",
    "print(f\"Offspring2: {offspring2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent 1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Parent 2: Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "\n",
      "Offspring1: Individual: nn_gene = [577, 256.1603071846655], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [577, 256], Fitness = 0.0\n",
      "Offspring2: Individual: nn_gene = [404.2829335178634, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [404, 431], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "# k = 0.5 is good, k = 0 is intermediate recombination \n",
    "def structure_SPC_lineRecombination(parent1, parent2, k, lb, ub):\n",
    "    gene1, gene2 = parent1.structure_gene, parent2.structure_gene\n",
    "    af_gene1, af_gene2 = parent1.af_gene, parent2.af_gene\n",
    "    lr_gene1, lr_gene2 = parent1.lr_gene, parent2.lr_gene\n",
    "    \n",
    "    # Determine the fittest parent\n",
    "    if parent1.fitness < parent2.fitness:\n",
    "        fitter_parent = parent1\n",
    "        other_parent = parent2\n",
    "    else:\n",
    "        fitter_parent = parent2\n",
    "        other_parent = parent1\n",
    "\n",
    "    if len(gene1) == 1 or len(gene2) == 1:\n",
    "        return parent1, parent2  # No crossover if a parent has only one layer\n",
    "    \n",
    "    point = random.randint(1, min(len(gene1), len(gene2)) - 1)\n",
    "    \n",
    "    # Split genes at the crossover point\n",
    "    first_part_fitter = fitter_parent.structure_gene[:point]\n",
    "    second_part_fitter = fitter_parent.structure_gene[point:]\n",
    "    \n",
    "    first_part_other = other_parent.structure_gene[:point]\n",
    "    second_part_other = other_parent.structure_gene[point:]\n",
    "    \n",
    "    # Compute averages for the second part of genes\n",
    "\n",
    "    max_len_first_part = max(len(first_part_fitter), len(first_part_other))\n",
    "    max_len_second_part = max(len(second_part_fitter), len(second_part_other))\n",
    "    ks_first_part =  [random.uniform(-k, 1 + k) for _ in range(max_len_first_part)]\n",
    "    ks_second_part =  [random.uniform(-k, 1 + k) for _ in range(max_len_second_part)]\n",
    "    \n",
    "    line_recombination_first_part = [\n",
    "        kk * a + (1 - kk) * b\n",
    "        for a, b, kk in zip(first_part_other, first_part_fitter, ks_first_part)]\n",
    "    line_recombination_second_part = [\n",
    "        kk * a + (1 - kk) * b\n",
    "        for a, b, kk in zip(second_part_other, second_part_fitter, ks_second_part)]\n",
    "    \n",
    "    \n",
    "    # Create new genes for the children\n",
    "    child_gene1 = first_part_fitter + line_recombination_second_part\n",
    "    child_gene2 = line_recombination_first_part + second_part_fitter\n",
    "\n",
    "    child_gene1 = correct_layers_size(genotype=child_gene1, lb=lb, ub=ub)\n",
    "    child_gene2 = correct_layers_size(genotype=child_gene2, lb=lb, ub=ub)\n",
    "    \n",
    "    # Create child individuals\n",
    "    child1 = Individual(structure_gene=child_gene1, af_gene=af_gene1, lr_gene =lr_gene1, dropout_gene=parent1.dropout_gene)\n",
    "    child2 = Individual(structure_gene=child_gene2, af_gene=af_gene2, lr_gene =lr_gene2, dropout_gene=parent2.dropout_gene)\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "# Example usage\n",
    "parent1 = population[0]\n",
    "parent2 = population[2]\n",
    "k = 0\n",
    "lb = 16\n",
    "ub = np.inf\n",
    "offspring1, offspring2 = structure_SPC_lineRecombination(parent1 = parent1, parent2 = parent2, k = k, lb = lb, ub = ub )\n",
    "\n",
    "\n",
    "print(f\"Parent 1: {parent1}\")\n",
    "print(f\"Parent 2: {parent2}\")\n",
    "print(f\"\\nOffspring1: {offspring1}\")\n",
    "print(f\"Offspring2: {offspring2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent 1: 377\n",
      "Parent 2: 577\n",
      "\n",
      "Offspring1: [554.8414360715755]\n",
      "Offspring2: [499.33229603159907]\n"
     ]
    }
   ],
   "source": [
    "# k = 0.5 is good, k = 0 is intermediate recombination \n",
    "def structure_lineRecombination_oneLayer(parent1, parent2, k, lb, ub):\n",
    "    gene1, gene2 = parent1.structure_gene[0], parent2.structure_gene[0]\n",
    "        \n",
    "    # Exctract two random point in (-k, 1+k)\n",
    "    k1 = random.uniform(-k, 1 + k)\n",
    "    k2 = random.uniform(-k, 1 + k)\n",
    "    \n",
    "    mutated_gene1 = k1 * gene1 + (1 - k1) * gene2\n",
    "    mutated_gene2 = k2 * gene1 + (1 - k2) * gene2\n",
    "\n",
    "    # Correct layer size \n",
    "    mutated_gene1 = correct_layer_size(gene = mutated_gene1, lb = lb, ub = ub)\n",
    "    mutated_gene2 = correct_layer_size(gene = mutated_gene2, lb = lb, ub = ub)\n",
    "    \n",
    "    # Create child individuals\n",
    "    child1 = Individual(structure_gene=[mutated_gene1], af_gene=parent1.af_gene, lr_gene =parent1.lr_gene, dropout_gene=parent1.dropout_gene)\n",
    "    child2 = Individual(structure_gene=[mutated_gene2], af_gene=parent2.af_gene, lr_gene =parent2.lr_gene, dropout_gene=parent2.dropout_gene)\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "# Example usage\n",
    "parent1 = population[0]\n",
    "parent2 = population[2]\n",
    "k = 0\n",
    "lb = 16\n",
    "ub = np.inf\n",
    "offspring1, offspring2 = structure_lineRecombination_oneLayer(parent1 = parent1, parent2 = parent2, k = k, lb = lb, ub = ub )\n",
    "\n",
    "\n",
    "print(f\"Parent 1: {parent1.structure_gene[0]}\")\n",
    "print(f\"Parent 2: {parent2.structure_gene[0]}\")\n",
    "\n",
    "print(f\"\\nOffspring1: {offspring1.structure_gene}\")\n",
    "print(f\"Offspring2: {offspring2.structure_gene}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent 1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Parent 2: Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "\n",
      "Offspring1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.0\n",
      "Offspring2: Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "def af_crossover(parent1, parent2, p_pick_the_best):\n",
    "\n",
    "    # Find the af of the fittest parent\n",
    "    if parent1.fitness < parent2.fitness:\n",
    "        af1 = parent1.af_gene # af of the fittest parent\n",
    "        af2 = parent2.af_gene\n",
    "    else:\n",
    "        af1 = parent2.af_gene\n",
    "        af2 = parent1.af_gene\n",
    "\n",
    "    # Define two individuals with a probability p to pick the af of the fittest parent\n",
    "    if random.random() < p_pick_the_best:\n",
    "        child1 = Individual(structure_gene=parent1.structure_gene, af_gene=af1, lr_gene=parent1.lr_gene, dropout_gene=parent1.dropout_gene)\n",
    "        child2 = Individual(structure_gene=parent2.structure_gene, af_gene=af1, lr_gene=parent2.lr_gene, dropout_gene=parent2.dropout_gene)\n",
    "    else:\n",
    "        child1 = Individual(structure_gene=parent1.structure_gene, af_gene=af2, lr_gene=parent1.lr_gene, dropout_gene=parent1.dropout_gene)\n",
    "        child2 = Individual(structure_gene=parent2.structure_gene, af_gene=af2, lr_gene=parent2.lr_gene, dropout_gene=parent2.dropout_gene)\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "# Example usage\n",
    "parent1 = population[0]\n",
    "parent2 = population[1]\n",
    "\n",
    "p_pick_the_best = 0.5\n",
    "\n",
    "offspring1, offspring2 = af_crossover(parent1, parent2, p_pick_the_best)\n",
    "\n",
    "print(f\"Parent 1: {parent1}\")\n",
    "print(f\"Parent 2: {parent2}\")\n",
    "print(f\"\\nOffspring1: {offspring1}\")\n",
    "print(f\"Offspring2: {offspring2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent 1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Parent 2: Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "\n",
      "Offspring1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.0035941554680799614, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.0\n",
      "Offspring2: Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.003578895639747029, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "def lr_linearRecombination(parent1, parent2, k, lb, ub):\n",
    "\n",
    "    gene1 = parent1.lr_gene\n",
    "    gene2 = parent2.lr_gene\n",
    "    a1 = np.random.uniform(-k, 1 + k)\n",
    "    a2 = np.random.uniform(-k, 1 + k)\n",
    "\n",
    "    child_gene1 = a1 * gene1 + (1 - a1) * gene2\n",
    "    child_gene2 = a2 * gene1 + (1 - a2) * gene2    \n",
    "\n",
    "    # correct lr size \n",
    "    child_gene1 = correct_general_size(value = child_gene1, ub = ub, lb = lb)\n",
    "    child_gene2 = correct_general_size(value = child_gene2, ub = ub, lb = lb)\n",
    "\n",
    "    child1 = Individual(structure_gene=parent1.structure_gene, af_gene=parent1.af_gene, lr_gene=child_gene1, dropout_gene=parent1.dropout_gene)\n",
    "    child2 = Individual(structure_gene=parent2.structure_gene, af_gene=parent2.af_gene, lr_gene=child_gene2, dropout_gene=parent2.dropout_gene)\n",
    "                           \n",
    "    return child1, child2\n",
    "\n",
    "# Example usage:\n",
    "parent1 = population[0]\n",
    "parent2 = population[1]\n",
    "k = 0\n",
    "lb = 0.0001\n",
    "ub = 0.1\n",
    "\n",
    "offspring1, offspring2 = lr_linearRecombination(parent1, parent2, k, lb, ub)\n",
    "\n",
    "print(f\"Parent 1: {parent1}\")\n",
    "print(f\"Parent 2: {parent2}\")\n",
    "print(f\"\\nOffspring1: {offspring1}\")\n",
    "print(f\"Offspring2: {offspring2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent 1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Parent 2: Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "\n",
      "Offspring1: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.13739865750603286 | nn_sol = [377, 127, 570, 19], Fitness = 0.0\n",
      "Offspring2: Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.1142030135371404 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "def dropout_linearRecombination(parent1, parent2, k, lb, ub):\n",
    "\n",
    "    gene1 = parent1.dropout_gene\n",
    "    gene2 = parent2.dropout_gene\n",
    "    a1 = np.random.uniform(-k, 1 + k)\n",
    "    a2 = np.random.uniform(-k, 1 + k)\n",
    "\n",
    "    child_gene1 = a1 * gene1 + (1 - a1) * gene2\n",
    "    child_gene2 = a2 * gene1 + (1 - a2) * gene2    \n",
    "\n",
    "    # correct lr size \n",
    "    child_gene1 = correct_general_size(value = child_gene1, ub = ub, lb = lb)\n",
    "    child_gene2 = correct_general_size(value = child_gene2, ub = ub, lb = lb)\n",
    "\n",
    "    child1 = Individual(structure_gene=parent1.structure_gene, af_gene=parent1.af_gene, lr_gene=parent1.lr_gene, dropout_gene=child_gene1)\n",
    "    child2 = Individual(structure_gene=parent2.structure_gene, af_gene=parent2.af_gene, lr_gene=parent2.lr_gene, dropout_gene=child_gene2)\n",
    "                           \n",
    "    return child1, child2\n",
    "\n",
    "# Example usage:\n",
    "parent1 = population[0]\n",
    "parent2 = population[1]\n",
    "k = 0\n",
    "lb = 0.0\n",
    "ub = 0.2\n",
    "\n",
    "offspring1, offspring2 = dropout_linearRecombination(parent1, parent2, k, lb, ub)\n",
    "\n",
    "print(f\"Parent 1: {parent1}\")\n",
    "print(f\"Parent 2: {parent2}\")\n",
    "print(f\"\\nOffspring1: {offspring1}\")\n",
    "print(f\"Offspring2: {offspring2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutation operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population:\n",
      "Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.02613769203890115\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.030617032636655495\n",
      "\n",
      "Genotype mean:\n",
      "[420.8, 351.0, 397.25, 171.75, 167.33333333333334]\n",
      "\n",
      "Genotype max:\n",
      "[577, 431, 570, 571, 322]\n"
     ]
    }
   ],
   "source": [
    "def structure_PP_selfAdaptiveMutation(population):\n",
    "    # Find the maximum lenght of the genes of the population \n",
    "    max_len = max([len(ind.structure_gene) for ind in population])\n",
    "\n",
    "    # Find the mean of each gene of the genotype\n",
    "    genotype_mean = [np.mean([ind.structure_gene[i] for ind in population if i < len(ind.structure_gene)]) for i in range(max_len)]\n",
    "\n",
    "    # Find the maximum of each gene of the genotype\n",
    "    genotype_max = [np.max([ind.structure_gene[i] for ind in population if i < len(ind.structure_gene)]) for i in range(max_len)]\n",
    "\n",
    "    return genotype_mean, genotype_max\n",
    "\n",
    "# Example usage\n",
    "#population: defined before\n",
    "genotype_mean, genotype_max = structure_PP_selfAdaptiveMutation(population)\n",
    "\n",
    "print(\"Population:\")\n",
    "for individual in population:\n",
    "    print(individual)\n",
    "\n",
    "print(\"\\nGenotype mean:\")\n",
    "print(genotype_mean)    \n",
    "\n",
    "print(\"\\nGenotype max:\")\n",
    "print(genotype_max)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gentype mean: [420.8, 351.0, 397.25, 171.75, 167.33333333333334]\n",
      "\n",
      "Gene: 377 -> 364.1901375281292\n",
      "Gene: 127 -> 116.46529701693716\n",
      "Gene: 570 -> 595.8368140062012\n",
      "Gene: 19 -> 25.876282420635082\n"
     ]
    }
   ],
   "source": [
    "def structure_selfAdaptiveGaussianMutation(parent, genotype_mean, lb, ub):\n",
    "    gene = parent.structure_gene\n",
    "    mutated_gene = []\n",
    "    for i in range(len(gene)):\n",
    "        mutated_gene.append(gene[i] + np.random.normal(0, genotype_mean[i]/10))\n",
    "        mutated_gene[i] = correct_layer_size(gene=mutated_gene[i], lb=lb, ub=ub)\n",
    "    return Individual(structure_gene=mutated_gene, af_gene=parent.af_gene, lr_gene=parent.lr_gene, dropout_gene=parent.dropout_gene)  \n",
    "    \n",
    "# Example usage\n",
    "parent = population[0]\n",
    "#genotype_mean: defined before\n",
    "lb = 16\n",
    "ub = np.inf\n",
    "\n",
    "mutated_individual = structure_selfAdaptiveGaussianMutation(parent=parent, genotype_mean=genotype_mean, lb=lb, ub=ub)\n",
    "\n",
    "print(f\"Gentype mean: {genotype_mean}\\n\")\n",
    "\n",
    "for g1, g2 in zip(parent.structure_gene, mutated_individual.structure_gene):\n",
    "    print(f\"Gene: {g1} -> {g2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Mutated individual: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.ELU'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "def af_mutation(parent, activation_functions, p_change_af):\n",
    "    gene = parent.af_gene\n",
    "    if random.random() < p_change_af:\n",
    "        gene = random.choice(activation_functions)\n",
    "    return Individual(structure_gene=parent.structure_gene, af_gene=gene, lr_gene=parent.lr_gene, dropout_gene=parent.dropout_gene)\n",
    "\n",
    "# Example usage\n",
    "parent = population[0]\n",
    "activation_functions = [nn.ReLU, nn.Sigmoid, nn.Tanh, nn.LeakyReLU, nn.ELU, nn.SELU]\n",
    "p_change_af = 0.5\n",
    "\n",
    "mutated_individual = af_mutation(parent=parent, activation_functions=activation_functions, p_change_af=p_change_af)\n",
    "\n",
    "print(f\"Parent: {parent}\")\n",
    "print(f\"Mutated individual: {mutated_individual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population:\n",
      "Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.02613769203890115\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.030617032636655495\n",
      "\n",
      "Learning rate mean: 0.0038970885617401604\n"
     ]
    }
   ],
   "source": [
    "def lr_PP_selfAdaptiveMutation(population):\n",
    "    # Find the mean of the learning rates of the population\n",
    "    lr_mean = np.mean([ind.lr_gene for ind in population])\n",
    "    return lr_mean\n",
    "\n",
    "# Example usage\n",
    "#population: defined before\n",
    "\n",
    "lr_mean = lr_PP_selfAdaptiveMutation(population)\n",
    "\n",
    "print(\"Population:\")\n",
    "for individual in population:\n",
    "    print(individual)\n",
    "\n",
    "print(f\"\\nLearning rate mean: {lr_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population:\n",
      "0.14571091681565093\n",
      "0.011325486426682697\n",
      "0.004836673466477404\n",
      "0.03699075371346252\n",
      "0.12017907756079112\n",
      "\n",
      "Learning rate mean: 0.06380858159661293\n"
     ]
    }
   ],
   "source": [
    "def dropout_PP_selfAdaptiveMutation(population):\n",
    "    # Find the mean of the learning rates of the population\n",
    "    dropout_mean = np.mean([ind.dropout_gene for ind in population])\n",
    "    return dropout_mean\n",
    "\n",
    "# Example usage\n",
    "#population: defined before\n",
    "\n",
    "dropout_mean = dropout_PP_selfAdaptiveMutation(population)\n",
    "\n",
    "print(\"Population:\")\n",
    "for individual in population:\n",
    "    print(individual.dropout_gene)\n",
    "\n",
    "print(f\"\\nLearning rate mean: {dropout_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent: 0.004069676109614568\n",
      "lr mean: 0.0038970885617401604\n",
      "\n",
      "Mutated individual: 0.0035660029175216216\n"
     ]
    }
   ],
   "source": [
    "def lr_selfAdaptiveGaussianMutation(parent, lr_mean, lb, ub):\n",
    "    gene = parent.lr_gene\n",
    "    mutated_gene = gene + np.random.normal(0, lr_mean/10)\n",
    "    mutated_gene = correct_general_size(value=mutated_gene, lb=lb, ub=ub)\n",
    "    return Individual(structure_gene=parent.structure_gene, af_gene=parent.af_gene, lr_gene=mutated_gene, dropout_gene=parent.dropout_gene)\n",
    "\n",
    "# Example usage\n",
    "parent = population[0]\n",
    "#lr_mean: defined before\n",
    "lb = 0.0001\n",
    "ub = 0.01\n",
    "\n",
    "mutated_individual = lr_selfAdaptiveGaussianMutation(parent=parent, lr_mean=lr_mean, lb=lb, ub=ub)\n",
    "\n",
    "print(f\"Parent: {parent.lr_gene}\")\n",
    "print(f\"lr mean: {lr_mean}\")\n",
    "\n",
    "print(f\"\\nMutated individual: {mutated_individual.lr_gene}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent: 0.14571091681565093\n",
      "lr mean: 0.06380858159661293\n",
      "\n",
      "Mutated individual: 0.1449278152385735\n"
     ]
    }
   ],
   "source": [
    "def dropout_selfAdaptiveGaussianMutation(parent, dropout_mean, lb, ub):\n",
    "    gene = parent.dropout_gene\n",
    "    mutated_gene = gene + np.random.normal(0, dropout_mean/10)\n",
    "    mutated_gene = correct_general_size(value=mutated_gene, lb=lb, ub=ub)\n",
    "    return Individual(structure_gene=parent.structure_gene, af_gene=parent.af_gene, lr_gene=parent.lr_gene, dropout_gene=mutated_gene)\n",
    "\n",
    "# Example usage\n",
    "parent = population[0]\n",
    "#dropout_mean: defined before\n",
    "lb = 0.0\n",
    "ub = 0.2\n",
    "\n",
    "mutated_individual = dropout_selfAdaptiveGaussianMutation(parent=parent, dropout_mean=dropout_mean, lb=lb, ub=ub)\n",
    "\n",
    "print(f\"Parent: {parent.dropout_gene}\")\n",
    "print(f\"lr mean: {dropout_mean}\")\n",
    "\n",
    "print(f\"\\nMutated individual: {mutated_individual.dropout_gene}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Mutated individual: Individual: nn_gene = [377, 127, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 19], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "# This mutation removes a gene\n",
    "def structure_shrink_mutation(individual):\n",
    "    mutated_gene = individual.structure_gene.copy()\n",
    "    if len(mutated_gene) <= 1:\n",
    "        return Individual(structure_gene=mutated_gene, af_gene=individual.af_gene, lr_gene=individual.lr_gene, dropout_gene=individual.dropout_gene)\n",
    "    \n",
    "    index = random.randint(0, len(mutated_gene) - 1)\n",
    "    mutated_gene.pop(index)\n",
    "    \n",
    "    return Individual(structure_gene=mutated_gene, af_gene=individual.af_gene, lr_gene=individual.lr_gene, dropout_gene=individual.dropout_gene)  \n",
    "\n",
    "# Example usage\n",
    "individual = population[0]\n",
    "mutated_individual = structure_shrink_mutation(individual)\n",
    "\n",
    "print(f\"Individual: {individual}\")\n",
    "print(f\"Mutated individual: {mutated_individual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotype mean: [420.8, 351.0, 397.25, 171.75, 167.33333333333334]\n",
      "\n",
      "Individual: Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Mutated individual: Individual: nn_gene = [479.5525087625506, 377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [480, 377, 127, 570, 19], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "# This mutation adds a gene\n",
    "def structure_gaussianGrowMutation(individual, genotype_mean, position, lb, ub):\n",
    "    mutated_gene = individual.structure_gene.copy()\n",
    "    \n",
    "    # Determine the index to insert the new gene \n",
    "    if position == 'beginning':\n",
    "        index = 0\n",
    "    elif position == 'end':\n",
    "        index = len(mutated_gene)\n",
    "    else:  # Default to inserting at a random position\n",
    "        index = random.randint(0, len(mutated_gene))\n",
    "\n",
    "    # If condition \n",
    "    # It can happen that the new layer is the last one AND the largest individual has less number of layer \n",
    "    # So, we don't have data on the average of the population for that position  \n",
    "    if index == len(mutated_gene) and len(mutated_gene) >= len(genotype_mean):\n",
    "        inspiration_index = random.randint(0, len(genotype_mean) - 1) # Randomly select an index from the genotype\n",
    "        new_layer_size = np.random.normal(genotype_mean[inspiration_index], genotype_mean[inspiration_index]/10)\n",
    "        new_layer_size = correct_layer_size(gene=new_layer_size, lb=lb, ub=ub)\n",
    "        mutated_gene.insert(index, new_layer_size)\n",
    "    else:\n",
    "        new_layer_size = np.random.normal(genotype_mean[index], genotype_mean[index]/10)\n",
    "        new_layer_size = correct_layer_size(gene=new_layer_size, lb=lb, ub=ub)\n",
    "        mutated_gene.insert(index, new_layer_size)\n",
    "    \n",
    "    return Individual(structure_gene=mutated_gene, af_gene=individual.af_gene, lr_gene=individual.lr_gene, dropout_gene=individual.dropout_gene)\n",
    "\n",
    "# Example usage\n",
    "individual = population[0]\n",
    "#genotype_max: defined before\n",
    "#genotype_mean: defined before\n",
    "position = 'random'\n",
    "lb = 16\n",
    "ub = np.inf\n",
    "\n",
    "mutated_individual = structure_gaussianGrowMutation(individual=individual, genotype_mean=genotype_mean, position=position, lb=lb, ub=ub)\n",
    "\n",
    "print(f\"Genotype mean: {genotype_mean}\\n\")\n",
    "\n",
    "print(f\"Individual: {individual}\")\n",
    "print(f\"Mutated individual: {mutated_individual}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Population:\n",
      "Individual: nn_gene = [377, 127, 570, 19], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.004069676109614568, dropout = 0.14571091681565093 | nn_sol = [377, 127, 570, 19], Fitness = 0.02857479895465076\n",
      "Individual: nn_gene = [519, 405, 441, 571, 102], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0031403936487633404, dropout = 0.011325486426682697 | nn_sol = [519, 405, 441, 571, 102], Fitness = 0.025355623802170157\n",
      "Individual: nn_gene = [577, 431], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0013496923819881865, dropout = 0.004836673466477404 | nn_sol = [577, 431], Fitness = 0.023562137386761606\n",
      "Individual: nn_gene = [337, 412, 395, 37, 78], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005359429848240019, dropout = 0.03699075371346252 | nn_sol = [337, 412, 395, 37, 78], Fitness = 0.02613769203890115\n",
      "Individual: nn_gene = [294, 380, 183, 60, 322], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.005566250820094688, dropout = 0.12017907756079112 | nn_sol = [294, 380, 183, 60, 322], Fitness = 0.030617032636655495\n",
      "\n",
      "Offsprings:\n",
      "Individual: nn_gene = [495.23028813533176], af = <class 'torch.nn.modules.activation.LeakyReLU'>, lr = 0.0040361445349095856, dropout = 0.03582401728299377 | nn_sol = [495], Fitness = 0.0\n",
      "Individual: nn_gene = [440.2571542672441], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.0027009786982734813, dropout = 0.13282237098761623 | nn_sol = [440], Fitness = 0.0\n",
      "Individual: nn_gene = [374.4391854014314], af = <class 'torch.nn.modules.activation.Sigmoid'>, lr = 0.005028431406083833, dropout = 0.09831216261620843 | nn_sol = [374], Fitness = 0.0\n",
      "Individual: nn_gene = [337.3520513115098], af = <class 'torch.nn.modules.activation.Tanh'>, lr = 0.005063481520119441, dropout = 0.1271558633908721 | nn_sol = [337], Fitness = 0.0\n"
     ]
    }
   ],
   "source": [
    "def generate_offsprings(\n",
    "        population,\n",
    "        number_of_offsprings,\n",
    "        tournament_percentage,\n",
    "        p_crossover_vs_mutation,\n",
    "        structure_k_crossover,\n",
    "        structure_lb_size,\n",
    "        structure_ub_size,\n",
    "        #af_p_pick_the_best,\n",
    "        lr_k,\n",
    "        dropout_k,\n",
    "        #p_changeLength_mutation,\n",
    "        #structure_grow_position,\n",
    "        #activation_functions,\n",
    "        #af_p_change_af,\n",
    "        lr_lb,\n",
    "        lr_ub,\n",
    "        dropout_lb,\n",
    "        dropout_ub):\n",
    "    \n",
    "    offsprings = []\n",
    "\n",
    "    # Pre-process the population\n",
    "    structure_genotype_mean, _ = structure_PP_selfAdaptiveMutation(population=population)\n",
    "    lr_genotype_mean = lr_PP_selfAdaptiveMutation(population=population)\n",
    "    dropout_genotype_mean = dropout_PP_selfAdaptiveMutation(population=population)\n",
    "\n",
    "    for _ in range(number_of_offsprings // 2):\n",
    "        # Select parents for crossover\n",
    "        parent1, parent2 = tournament_selection(population = population, number_of_selected=2, percentage_of_population_size=tournament_percentage, heterogeneity=True)\n",
    "\n",
    "        if random.random() < p_crossover_vs_mutation:\n",
    "            offspring1, offspring2 = structure_lineRecombination_oneLayer(parent1=parent1, parent2=parent2, k=structure_k_crossover, lb=structure_lb_size, ub=structure_ub_size)\n",
    "            offspring1, offspring2 = lr_linearRecombination(parent1=offspring1, parent2=offspring2, k = lr_k, lb = lr_lb, ub =lr_ub)\n",
    "            offspring1, offspring2 = dropout_linearRecombination(parent1=offspring1, parent2=offspring2, k = dropout_k, lb = dropout_lb, ub =dropout_ub)\n",
    "        else:\n",
    "            offspring1 = structure_selfAdaptiveGaussianMutation(parent = parent1, genotype_mean=structure_genotype_mean, lb = structure_lb_size, ub = structure_ub_size)\n",
    "            offspring2 = structure_selfAdaptiveGaussianMutation(parent = parent2, genotype_mean=structure_genotype_mean, lb = structure_lb_size, ub = structure_ub_size)\n",
    "\n",
    "            offspring1 = lr_selfAdaptiveGaussianMutation(parent = offspring1, lr_mean = lr_genotype_mean, lb = lr_lb, ub =lr_ub)\n",
    "            offspring2 = lr_selfAdaptiveGaussianMutation(parent = offspring2, lr_mean = lr_genotype_mean, lb = lr_lb, ub =lr_ub)\n",
    "\n",
    "            offspring1 = dropout_selfAdaptiveGaussianMutation(parent = offspring1, dropout_mean = dropout_genotype_mean, lb = dropout_lb, ub =dropout_ub)\n",
    "            offspring2 = dropout_selfAdaptiveGaussianMutation(parent = offspring2, dropout_mean = dropout_genotype_mean, lb = dropout_lb, ub =dropout_ub)\n",
    "\n",
    "        # Add the offspring to the population\n",
    "        offsprings.append(offspring1)\n",
    "        offsprings.append(offspring2)\n",
    "            \n",
    "    # If it is odd\n",
    "    if number_of_offsprings % 2 == 1:\n",
    "        parent = tournament_selection(population = population, number_of_selected = 1, percentage_of_population_size = tournament_percentage, heterogeneity=False)[0]\n",
    "        offspring = structure_selfAdaptiveGaussianMutation(parent = parent, genotype_mean = structure_genotype_mean, lb = structure_lb_size, ub = structure_ub_size)\n",
    "        offspring = lr_selfAdaptiveGaussianMutation(parent = offspring, lr_mean = lr_genotype_mean, lb = lr_lb, ub =lr_ub)\n",
    "        offspring = dropout_selfAdaptiveGaussianMutation(parent = offspring, dropout_mean = dropout_genotype_mean, lb = dropout_lb, ub =dropout_ub)\n",
    "        offsprings.append(offspring)    \n",
    "\n",
    "    return offsprings\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "#population: defined before\n",
    "number_of_offsprings = 4\n",
    "tournament_percentage = 0.2\n",
    "p_crossover_vs_mutation = 0.5\n",
    "structure_k_crossover = 0\n",
    "structure_lb_size = 16\n",
    "structure_ub_size = np.inf\n",
    "lr_k = 0\n",
    "dropout_k = 0\n",
    "lr_lb = 0.0001\n",
    "lr_ub = 0.1\n",
    "dropout_lb = 0.0\n",
    "dropout_ub = 0.2\n",
    "\n",
    "offsprings = generate_offsprings(\n",
    "    population = population,\n",
    "    number_of_offsprings = number_of_offsprings,\n",
    "    tournament_percentage = tournament_percentage,\n",
    "    p_crossover_vs_mutation = p_crossover_vs_mutation,\n",
    "    structure_k_crossover = structure_k_crossover,\n",
    "    structure_lb_size = structure_lb_size,\n",
    "    structure_ub_size = structure_ub_size,\n",
    "    lr_k = lr_k,\n",
    "    dropout_k = dropout_k,\n",
    "    lr_lb = lr_lb,\n",
    "    lr_ub = lr_ub,\n",
    "    dropout_lb = dropout_lb,\n",
    "    dropout_ub = dropout_ub)\n",
    "\n",
    "print(\"\\nPopulation:\")\n",
    "for individual in population:\n",
    "    print(individual)\n",
    "\n",
    "print(\"\\nOffsprings:\")\n",
    "for offspring in offsprings:\n",
    "    print(offspring)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es lambda mu for structure (s), learning rate (l) and dropout (d) in the classification case\n",
    "\n",
    "def es_lambdaMu_sld_regression(\n",
    "        max_fitness_evaluations,\n",
    "        mu_population_size,\n",
    "        init_layersNumber_interval,\n",
    "        init_unitsNumber_interval,\n",
    "        init_activation_functions,\n",
    "        init_lr_interval,\n",
    "        init_dropout_interval,\n",
    "        nn_training_data,\n",
    "        nn_validation_data,\n",
    "        num_epochs_per_nn_evaluation,\n",
    "        #nn_learning_rate,\n",
    "        nn_input_size,\n",
    "        #nn_hidden_sizes,\n",
    "        nn_output_size,\n",
    "        #nn_activation_function,\n",
    "        #nn_initialize_weights,\n",
    "        device,\n",
    "        maximize_fitness,\n",
    "        lambda_offsprings_size,\n",
    "        tornamentPercentage_for_offspringGeneration,\n",
    "        p_crossover_vs_mutation,\n",
    "        structure_k_value_for_crossover,\n",
    "        structure_lb_size,\n",
    "        structure_ub_size,\n",
    "        #af_p_pick_the_best,\n",
    "        lr_k,\n",
    "        dropout_k,\n",
    "        #structure_p_changeLength_mutation,\n",
    "        #structure_grow_position,\n",
    "        #af_p_change_af,\n",
    "        lr_lb,\n",
    "        lr_ub,\n",
    "        dropout_lb,\n",
    "        dropout_ub):\n",
    "    \n",
    "\n",
    "    # Initialize the population\n",
    "    fitness_evaluations = 0\n",
    "    gen_index = 1\n",
    "\n",
    "    population = initialization(\n",
    "        initial_population_size = mu_population_size,\n",
    "        number_of_layers_interval = init_layersNumber_interval,\n",
    "        number_of_units_interval = init_unitsNumber_interval,\n",
    "        activation_functions = init_activation_functions,\n",
    "        learning_rate_interval = init_lr_interval,\n",
    "        dropout_interval = init_dropout_interval)\n",
    "    \n",
    "    print(\"\\nInitial population:\")\n",
    "    for individual in population:\n",
    "        print(individual)\n",
    "\n",
    "    # Evaluate the individuals\n",
    "    evaluate_individuals(\n",
    "        individuals = population,\n",
    "        training_data = nn_training_data,\n",
    "        validation_data = nn_validation_data,\n",
    "        num_epochs_per_evaluation = num_epochs_per_nn_evaluation,\n",
    "        #lr,\n",
    "        input_size = nn_input_size, # 40\n",
    "        #hidden_sizes,\n",
    "        output_size = nn_output_size, # 15\n",
    "        #activation_function,\n",
    "        #initialize_weights,\n",
    "        #dropout,\n",
    "        device = device)\n",
    "    \n",
    "    fitness_evaluations += mu_population_size\n",
    "    \n",
    "    # Print first results\n",
    "    best_individuals = []\n",
    "    best_individual = find_best_individual(population = population, maximize = maximize_fitness)\n",
    "    best_individuals.append(best_individual)\n",
    "\n",
    "    print(f\"\\nGeneration: {gen_index} | Fitness evalutions: {fitness_evaluations} | Best individual: {best_individual}\")\n",
    "    # Print population in from the fitted individuals to the worst\n",
    "    for ind in sorted(population, key=lambda ind: ind.fitness):\n",
    "        print(ind)\n",
    "\n",
    "    # Evolution loop\n",
    "    while fitness_evaluations < max_fitness_evaluations:\n",
    "\n",
    "        # Select offsprings \n",
    "        offsprings = generate_offsprings(\n",
    "            population = population,\n",
    "            number_of_offsprings = lambda_offsprings_size,\n",
    "            tournament_percentage = tornamentPercentage_for_offspringGeneration,\n",
    "            p_crossover_vs_mutation = p_crossover_vs_mutation,\n",
    "            structure_k_crossover = structure_k_value_for_crossover,\n",
    "            structure_lb_size = structure_lb_size,\n",
    "            structure_ub_size = structure_ub_size,\n",
    "            #af_p_pick_the_best,\n",
    "            lr_k = lr_k,\n",
    "            dropout_k = dropout_k,\n",
    "            #p_changeLength_mutation,\n",
    "            #structure_grow_position,\n",
    "            #activation_functions,\n",
    "            #af_p_change_af,\n",
    "            lr_lb = lr_lb,\n",
    "            lr_ub = lr_ub,\n",
    "            dropout_lb = dropout_lb,\n",
    "            dropout_ub = dropout_ub)\n",
    "        \n",
    "\n",
    "        # Evaluate the individuals\n",
    "        evaluate_individuals(\n",
    "            individuals = offsprings,\n",
    "            training_data = nn_training_data,\n",
    "            validation_data = nn_validation_data,\n",
    "            num_epochs_per_evaluation = num_epochs_per_nn_evaluation,\n",
    "            #lr,\n",
    "            input_size = nn_input_size, # 40\n",
    "            #hidden_sizes,\n",
    "            output_size = nn_output_size, # 15\n",
    "            #activation_function,\n",
    "            #initialize_weights,\n",
    "            #dropout,\n",
    "            device = device)\n",
    "\n",
    "        fitness_evaluations += lambda_offsprings_size\n",
    "        \n",
    "        # Build new population\n",
    "        population = truncated_selection(\n",
    "            population = offsprings,\n",
    "            k = mu_population_size,\n",
    "            maximize = maximize_fitness)\n",
    "        \n",
    "        # Update the best individuals and print \n",
    "        best_individual = find_best_individual(population = population, maximize = maximize_fitness)\n",
    "        best_individuals.append(best_individual)\n",
    "        print(f\"\\nGeneration: {gen_index + 1} | Fitness evalutions: {fitness_evaluations} | Best individual: {best_individual}\")\n",
    "        for individual in population:\n",
    "            print(individual)\n",
    "        gen_index += 1\n",
    "\n",
    "\n",
    "    # Compute the best individual ever\n",
    "    best_individual_ever = find_best_individual(population = best_individuals, maximize = maximize_fitness)\n",
    "\n",
    "    return best_individual_ever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial population:\n",
      "Individual: nn_gene = [85], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.03954439812025269, dropout = 0.04744573074407754 | nn_sol = [85], Fitness = 0.0\n",
      "Individual: nn_gene = [29], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.0010362359483958256, dropout = 0.05934924930951235 | nn_sol = [29], Fitness = 0.0\n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 5.042858123779297, seconds\n",
      "Epoch 1/1, Train Loss: 0.22440168, Val Loss:  0.11001583, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 0.39963865280151367, seconds\n",
      "Epoch 1/1, Train Loss: 0.24263164, Val Loss:  0.04547822, \n",
      "\n",
      "Generation: 1 | Fitness evalutions: 2 | Best individual: Individual: nn_gene = [29], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.0010362359483958256, dropout = 0.05934924930951235 | nn_sol = [29], Fitness = 0.04547822367749177\n",
      "Individual: nn_gene = [29], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.0010362359483958256, dropout = 0.05934924930951235 | nn_sol = [29], Fitness = 0.04547822367749177\n",
      "Individual: nn_gene = [85], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.03954439812025269, dropout = 0.04744573074407754 | nn_sol = [85], Fitness = 0.11001583095639944\n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 2.19856333732605, seconds\n",
      "Epoch 1/1, Train Loss: 0.13503869, Val Loss:  0.03878873, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 1.6866676807403564, seconds\n",
      "Epoch 1/1, Train Loss: 0.12853512, Val Loss:  0.04114546, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 0.3745286464691162, seconds\n",
      "Epoch 1/1, Train Loss: 0.61407573, Val Loss:  0.28608899, \n",
      "\n",
      "Generation: 2 | Fitness evalutions: 5 | Best individual: Individual: nn_gene = [81.12542447640479], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.024152667448908895, dropout = 0.04752347991069951 | nn_sol = [81], Fitness = 0.03878873088979162\n",
      "Individual: nn_gene = [81.12542447640479], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.024152667448908895, dropout = 0.04752347991069951 | nn_sol = [81], Fitness = 0.03878873088979162\n",
      "Individual: nn_gene = [68.25045499168858], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.029158531869818587, dropout = 0.05371283460739897 | nn_sol = [68], Fitness = 0.04114545974880457\n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 1.3327429294586182, seconds\n",
      "Epoch 1/1, Train Loss: 0.11295118, Val Loss:  0.04301369, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 2.4896984100341797, seconds\n",
      "Epoch 1/1, Train Loss: 0.15480630, Val Loss:  0.04466314, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 3.642451047897339, seconds\n",
      "Epoch 1/1, Train Loss: 0.13674844, Val Loss:  0.03855628, \n",
      "\n",
      "Generation: 3 | Fitness evalutions: 8 | Best individual: Individual: nn_gene = [86.31508477476258], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.02862043082945085, dropout = 0.04530224034679009 | nn_sol = [86], Fitness = 0.038556275772862136\n",
      "Individual: nn_gene = [86.31508477476258], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.02862043082945085, dropout = 0.04530224034679009 | nn_sol = [86], Fitness = 0.038556275772862136\n",
      "Individual: nn_gene = [68.36013819134153], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.025979486430872306, dropout = 0.04927064262071551 | nn_sol = [68], Fitness = 0.043013687565689906\n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 3.31799054145813, seconds\n",
      "Epoch 1/1, Train Loss: 0.11918613, Val Loss:  0.03902606, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 2.196587085723877, seconds\n",
      "Epoch 1/1, Train Loss: 0.13368740, Val Loss:  0.03835605, \n",
      "Start training...\n",
      "\n",
      "[--------------------------------------------------] 0.0%  starting epoch 1\n",
      "Duration of training epoch 1: 4.046797037124634, seconds\n",
      "Epoch 1/1, Train Loss: 0.17930146, Val Loss:  0.07871879, \n",
      "\n",
      "Generation: 4 | Fitness evalutions: 11 | Best individual: Individual: nn_gene = [76.00674507264367], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.02641402134419195, dropout = 0.049098870288697034 | nn_sol = [76], Fitness = 0.03835604735650122\n",
      "Individual: nn_gene = [76.00674507264367], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.02641402134419195, dropout = 0.049098870288697034 | nn_sol = [76], Fitness = 0.03835604735650122\n",
      "Individual: nn_gene = [85.51482770915423], af = <class 'torch.nn.modules.activation.ReLU'>, lr = 0.028359389007213853, dropout = 0.04907957781480232 | nn_sol = [86], Fitness = 0.03902605903567746\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "max_fitness_evaluations = 10 # Just for trial\n",
    "num_epochs_per_nn_evaluation = 1\n",
    "\n",
    "mu_population_size = 2\n",
    "lambda_offsprings_size = 3\n",
    "\n",
    "init_layersNumber_interval = [1,1]\n",
    "init_unitsNumber_interval = [10,600] # change to 600\n",
    "init_activation_functions = [nn.ReLU] \n",
    "init_lr_interval = (0.0001, 0.1)\n",
    "init_dropout_interval = (0.0, 0.2)\n",
    "nn_training_data = dataloader_train\n",
    "nn_validation_data = dataloader_val\n",
    "nn_input_size = X_train.shape[1]\n",
    "nn_output_size = y_train.shape[1]\n",
    "device = 'cpu' # 'cuda'\n",
    "maximize_fitness = False\n",
    "\n",
    "tornamentPercentage_for_offspringGeneration = 0.2\n",
    "p_crossover_vs_mutation = 0.75\n",
    "structure_k_value_for_crossover = 0\n",
    "structure_lb_size = 10\n",
    "structure_ub_size = np.inf\n",
    "lr_k = 0\n",
    "dropout_k = 0\n",
    "lr_lb = 0.0001\n",
    "lr_ub = 0.1\n",
    "dropout_lb = 0.0\n",
    "dropout_ub = 0.2\n",
    "\n",
    "best_individual_ever = es_lambdaMu_sld_regression(\n",
    "    max_fitness_evaluations = max_fitness_evaluations,\n",
    "    mu_population_size = mu_population_size,\n",
    "    init_layersNumber_interval = init_layersNumber_interval,\n",
    "    init_unitsNumber_interval = init_unitsNumber_interval,\n",
    "    init_activation_functions = init_activation_functions,\n",
    "    init_lr_interval = init_lr_interval,\n",
    "    init_dropout_interval = init_dropout_interval,\n",
    "    nn_training_data = nn_training_data,\n",
    "    nn_validation_data = nn_validation_data,\n",
    "    num_epochs_per_nn_evaluation = num_epochs_per_nn_evaluation,\n",
    "    nn_input_size = nn_input_size,\n",
    "    nn_output_size = nn_output_size,\n",
    "    device = device,\n",
    "    maximize_fitness = maximize_fitness,\n",
    "    lambda_offsprings_size = lambda_offsprings_size,\n",
    "    tornamentPercentage_for_offspringGeneration = tornamentPercentage_for_offspringGeneration,\n",
    "    p_crossover_vs_mutation = p_crossover_vs_mutation,\n",
    "    structure_k_value_for_crossover = structure_k_value_for_crossover,\n",
    "    structure_lb_size = structure_lb_size,\n",
    "    structure_ub_size = structure_ub_size,\n",
    "    lr_k = lr_k,\n",
    "    dropout_k = dropout_k,\n",
    "    lr_lb = lr_lb,\n",
    "    lr_ub = lr_ub,\n",
    "    dropout_lb = dropout_lb,\n",
    "    dropout_ub = dropout_ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
